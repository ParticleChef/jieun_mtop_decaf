{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import json\n",
    "from coffea import processor, hist, util\n",
    "from coffea.util import save, load\n",
    "from optparse import OptionParser\n",
    "from coffea.lookup_tools.dense_lookup import dense_lookup\n",
    "import awkward as ak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTagEfficiency(processor.ProcessorABC):\n",
    "\n",
    "    def __init__(self, year,wp):\n",
    "        self._year = year\n",
    "        self._btagWPs = wp\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'deepflav' :\n",
    "            hist.Hist(\n",
    "                'Events',\n",
    "                hist.Cat('dataset', 'Dataset'),\n",
    "                hist.Cat('wp', 'Working point'),\n",
    "                hist.Cat('btag', 'BTag WP pass/fail'),\n",
    "                hist.Bin('flavor', 'Jet hadronFlavour', [0, 4, 5, 6]),\n",
    "                hist.Bin('pt', 'Jet pT', [20, 30, 50, 70, 100, 140, 200, 300, 600, 1000]),\n",
    "                hist.Bin('abseta', 'Jet abseta', [0, 1.4, 2.0, 2.5]),\n",
    "            ),\n",
    "            'deepcsv' :\n",
    "            hist.Hist(\n",
    "                'Events',\n",
    "                hist.Cat('dataset', 'Dataset'),\n",
    "                hist.Cat('wp', 'Working point'),\n",
    "                hist.Cat('btag', 'BTag WP pass/fail'),\n",
    "                hist.Bin('flavor', 'Jet hadronFlavour', [0, 4, 5, 6]),\n",
    "                hist.Bin('pt', 'Jet pT', [20, 30, 50, 70, 100, 140, 200, 300, 600, 1000]),\n",
    "                hist.Bin('abseta', 'Jet abseta', [0, 1.4, 2.0, 2.5]),\n",
    "            )\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, events):\n",
    "        \n",
    "        dataset = events.metadata['dataset']\n",
    "\n",
    "        jets = events.Jet[\n",
    "            (events.Jet.pt > 30.)\n",
    "            & (abs(events.Jet.eta) < 2.5)\n",
    "            & (events.Jet.jetId & 2)  # tight id\n",
    "        ]\n",
    "        \n",
    "        name = {}\n",
    "        name['deepflav']= 'btagDeepFlavB'\n",
    "        name['deepcsv']= 'btagDeepB'\n",
    "\n",
    "        out = self.accumulator.identity()\n",
    "\n",
    "        for wp in ['loose','medium','tight']:\n",
    "            for tagger in ['deepflav','deepcsv']:\n",
    "                passbtag = jets[name[tagger]] > self._btagWPs[tagger][self._year][wp]\n",
    "                out[tagger].fill(\n",
    "                    dataset=dataset,\n",
    "                    wp=wp,\n",
    "                    btag='pass',\n",
    "                    flavor=ak.flatten(jets[passbtag].hadronFlavour),\n",
    "                    pt=ak.flatten(jets[passbtag].pt),\n",
    "                    abseta=ak.flatten(abs(jets[passbtag].eta)),\n",
    "                )\n",
    "                out[tagger].fill(\n",
    "                    dataset=dataset,\n",
    "                    wp=wp,\n",
    "                    btag='fail',\n",
    "                    flavor=ak.flatten(jets[~passbtag].hadronFlavour),\n",
    "                    pt=ak.flatten(jets[~passbtag].pt),\n",
    "                    abseta=ak.flatten(abs(jets[~passbtag].eta)),\n",
    "                )\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, a):\n",
    "        return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = '2018'\n",
    "jsonfile = 'KIT_UL_2018_v3.json'\n",
    "\n",
    "with open('metadata/'+jsonfile) as fin:\n",
    "    samplefiles = json.load(fin)\n",
    "\n",
    "    common = load('data/common.coffea')\n",
    "    processor_instance=BTagEfficiency(year=year,wp=common['btagWPs'])\n",
    "\n",
    "    save(processor_instance, 'data/btagUL'+year+'.processor')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lz4.frame as lz4f\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import cloudpickle\n",
    "import gzip\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "from coffea.nanoevents import NanoAODSchema, NanoEventsFactory\n",
    "from coffea.nanoevents.methods import nanoaod\n",
    "\n",
    "NanoAODSchema.warn_missing_crossrefs = False\n",
    "import uproot\n",
    "import numpy as np\n",
    "from coffea import hist, processor\n",
    "from coffea.util import load, save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIT_UL_2018_v3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processor_name = 'btagUL2018'\n",
    "metadata = jsonfile.split('.')[0]\n",
    "print(metadata)\n",
    "datasets = False\n",
    "workers = 8\n",
    "\n",
    "processor_instance=load('data/'+processor_name+'.processor')\n",
    "\n",
    "fileslice = slice(None)\n",
    "with open(\"metadata/\"+metadata+\".json\") as fin:\n",
    "    samplefiles = json.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: QCD_Pt_800to1000_TuneCP5_13TeV_pythia8____14_\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6250ed8e197a4a66b115f9acb85c1ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/3 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4526139322.28 us*cpu overall\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset, info in samplefiles.items():\n",
    "    if not dataset == 'QCD_Pt_800to1000_TuneCP5_13TeV_pythia8____14_': continue\n",
    "    filelist = {}\n",
    "    if datasets and datasets not in dataset: continue\n",
    "    print('Processing:',dataset)\n",
    "    files = []\n",
    "    for file in info['files'][fileslice]:\n",
    "        files.append(file)\n",
    "    filelist[dataset] = files\n",
    "\n",
    "    tstart = time.time()\n",
    "    output = processor.run_uproot_job(filelist,\n",
    "                                      \"Events\",\n",
    "                                       processor_instance=processor_instance,\n",
    "                                       executor=processor.futures_executor,\n",
    "                                       executor_args={'schema': NanoAODSchema,'workers': workers},\n",
    "                                       )\n",
    "#     output = processor.run_uproot_job(filelist,\n",
    "#                                       treename='Events',\n",
    "#                                       processor_instance=processor_instance,\n",
    "#                                       executor=processor.futures_executor,\n",
    "#                                       executor_args={'nano': True, 'workers': options.workers},\n",
    "#                                       )\n",
    "    \n",
    "    #nbins = sum(sum(arr.size for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "    #nfilled = sum(sum(np.sum(arr > 0) for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "    #print(\"Filled %.1fM bins\" % (nbins/1e6, ))\n",
    "    #print(\"Nonzero bins: %.1f%%\" % (100*nfilled/nbins, ))\n",
    "\n",
    "    os.system(\"mkdir -p hists/\"+processor_name)\n",
    "    save(output,'hists/'+processor_name+'/'+dataset+'.futures')        \n",
    "    dt = time.time() - tstart\n",
    "    nworkers = workers\n",
    "    print(\"%.2f us*cpu overall\" % (1e6*dt*nworkers, ))                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
